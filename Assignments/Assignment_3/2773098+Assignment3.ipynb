{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knowledge and Data: Practical Assignment 3 \n",
    "## RDF Data, RDFS knowledge and inferencing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR NAME: My Vu\n",
    "\n",
    "YOUR VUNetID: mvu204\n",
    "\n",
    "*(If you do not provide your name and VUNetID we will not accept your submission).* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning objectives\n",
    "\n",
    "At the end of this exercise you should be able to:\n",
    "\n",
    "1. Access local an external data via SPARQL both from within a python programming environment and stand-alone with a GUI, such as [YASGUI](https://yasgui.triply.cc/), and this way integrate data from different sources  \n",
    "2. Model your own first knowledge base, in this case an RDF Schema knowledge graph\n",
    "3. Implement inference rules "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow this Notebook step-by-step. \n",
    "\n",
    "Of course, you can do the exercises in any Programming Editor of your liking. \n",
    "But you do not have to. Feel free to simply write code in the Notebook. When \n",
    "everythink is filled in and works, safe the Notebook and submit it \n",
    "as a Jupyter Notebook, i.e. with an ipynb extension. Please use as name of the \n",
    "Notebook your studentID+Assignment3.ipynb.  \n",
    "\n",
    "Other than in courses dedicated to programming we will not evaluate the style\n",
    "of the programs. But we will test your programs on other data than we provide, \n",
    "and your program should give the correct answers to those test-data as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you start, you need to:\n",
    "\n",
    "- **Install the *rdflib* Python package:** *pip install rdflib* (should already be installed from the previous assignment)\n",
    "- **Install the *SPARQLWrapper* Python package:** *pip install SPARQLWrapper*\n",
    "- **Install the free edition of the GraphDB Triplestore:** please follow this short [GraphDB tutorial](https://github.com/ucds-vu/knowledge-data-vu/blob/master/Tutorials/Preliminaries/tutorial-GraphDB.md). \n",
    "\n",
    "Then, add the file example-from-slides.ttl to a newly created database, say called assignment-3. \n",
    "\n",
    "**Note that you should have an active internet connection to run the code in this notebook.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: SPARQLWrapper in c:\\users\\thaom\\anaconda3\\envs\\knowledge\\lib\\site-packages (1.8.5)\n",
      "Requirement already satisfied: rdflib>=4.0 in c:\\users\\thaom\\anaconda3\\envs\\knowledge\\lib\\site-packages (from SPARQLWrapper) (6.2.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\thaom\\anaconda3\\envs\\knowledge\\lib\\site-packages (from rdflib>=4.0->SPARQLWrapper) (65.3.0)\n",
      "Requirement already satisfied: isodate in c:\\users\\thaom\\anaconda3\\envs\\knowledge\\lib\\site-packages (from rdflib>=4.0->SPARQLWrapper) (0.6.1)\n",
      "Requirement already satisfied: pyparsing in c:\\users\\thaom\\anaconda3\\envs\\knowledge\\lib\\site-packages (from rdflib>=4.0->SPARQLWrapper) (3.0.9)\n",
      "Requirement already satisfied: six in c:\\users\\thaom\\anaconda3\\envs\\knowledge\\lib\\site-packages (from isodate->rdflib>=4.0->SPARQLWrapper) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# install library\n",
    "%pip install SPARQLWrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: (3 points) Integrate Local and External Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can integrate SPARQL queries into your Python code by using the *RDFLib* and *SPARQLWrapper* libraries. \n",
    "\n",
    "The following code accesses the DBPedia knowledge graph using its SPARQL endpoint, and returns the result of the SPARQL query requesting all the labels asserted to Amsterdam (test it!)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amsterdam\n",
      "أمستردام\n",
      "حكومة أمستردام\n",
      "Amsterdam\n",
      "Amsterdam\n",
      "Άμστερνταμ (δήμος)\n",
      "Άμστερνταμ\n",
      "Amsterdam\n",
      "Amsterdamo\n",
      "Ámsterdam\n",
      "Amsterdam\n",
      "Amsterdam (commune)\n",
      "Amsterdam\n",
      "Amstardam\n",
      "Amsterdam\n",
      "アムステルダム\n",
      "Amsterdam\n",
      "암스테르담\n",
      "Amsterdam (gemeente)\n",
      "Amsterdam\n",
      "Amsterdam\n",
      "Amesterdão\n",
      "Амстердам\n",
      "Amsterdam\n",
      "Амстердам\n",
      "阿姆斯特丹\n"
     ]
    }
   ],
   "source": [
    "# This code only works if you are online\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "from rdflib import Graph, RDF, RDFS, Namespace, Literal, URIRef\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "sparql = SPARQLWrapper(\"http://dbpedia.org/sparql\")\n",
    "sparql.setQuery(\"\"\"\n",
    "    PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "    SELECT ?cityName\n",
    "    WHERE { \n",
    "        <http://dbpedia.org/resource/Amsterdam> rdfs:label ?cityName \n",
    "    }\n",
    "\"\"\")\n",
    "sparql.setReturnFormat(JSON)\n",
    "results = sparql.query().convert()\n",
    "for result in results[\"results\"][\"bindings\"]:\n",
    "    print(result[\"cityName\"][\"value\"])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your task is now the following:\n",
    "1. Write a SPARQL query that extracts all the cities from your local knowledge graph (constructed by loading the file example-from-slides.ttl) \n",
    "2. Find the number of inhabitants of these cities and the longitude and latitude information (if available) from DBPedia.\n",
    "3. Merge the triples from example-from-slides.ttl with the information extracted from DBpedia + Save all these triples into a new file 'extended-example.ttl' + Print all triples in Turtle Syntax.\n",
    "\n",
    "For your convenience, we already wrote the following functions that might be useful to complete this task. \n",
    "In addition, we have loaded and printed the 'example-from-slides.ttl' dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@prefix ex: <http://example.com/kad/> .\n",
      "@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .\n",
      "\n",
      "ex:Netherlands a ex:Country ;\n",
      "    ex:contains ex:Ijsselmeer ;\n",
      "    ex:containsCity ex:Rotterdam ;\n",
      "    ex:hasCapital ex:Amsterdam ;\n",
      "    ex:hasName \"The Netherlands\" ;\n",
      "    ex:neighbours ex:Belgium .\n",
      "\n",
      "ex:hasCapital rdfs:range ex:Capital ;\n",
      "    rdfs:subPropertyOf ex:containsCity .\n",
      "\n",
      "ex:neighbours rdfs:subPropertyOf ex:closeBy .\n",
      "\n",
      "ex:Amsterdam a ex:Capital ;\n",
      "    ex:closeBy ex:Germany .\n",
      "\n",
      "ex:Belgium a ex:Country .\n",
      "\n",
      "ex:EuropeanCountry rdfs:subClassOf ex:Country .\n",
      "\n",
      "ex:Germany a ex:EuropeanCountry ;\n",
      "    ex:hasCapital ex:Berlin .\n",
      "\n",
      "ex:closeBy rdfs:domain ex:Location ;\n",
      "    rdfs:range ex:Location .\n",
      "\n",
      "ex:containsCity rdfs:domain ex:Country ;\n",
      "    rdfs:range ex:City ;\n",
      "    rdfs:subPropertyOf ex:contains .\n",
      "\n",
      "ex:Capital rdfs:subClassOf ex:City .\n",
      "\n",
      "ex:City rdfs:subClassOf ex:Location .\n",
      "\n",
      "ex:Country rdfs:subClassOf ex:Location .\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from rdflib import Graph, RDF, Namespace, Literal, URIRef\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "\n",
    "# Loads the data from a certain file given as input in Turtle syntax into the Graph g  \n",
    "# -------------------------\n",
    "def load_graph(graph, filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        graph.parse(f, format='turtle')\n",
    "        \n",
    "\n",
    "# Prints a certain graph given as input in Turtle syntax\n",
    "# -------------------------\n",
    "def serialize_graph(myGraph):\n",
    "     print(myGraph.serialize(format='turtle'))\n",
    "        \n",
    "\n",
    "# Saves the Graph g in Turtle syntax to a certain file given as input\n",
    "# -------------------------\n",
    "def save_graph(myGraph, filename):\n",
    "    with open(filename, 'w') as f:\n",
    "        myGraph.serialize(filename, format='turtle')\n",
    "        \n",
    "    \n",
    "# Changes the namespace of a certain URI given as input to a DBpedia URI \n",
    "# Example: transformToDBR(\"http://example.com/kad2020/Amsterdam\") returns \"http://dbpedia.org/resource/Amsterdam\"\n",
    "# -------------------------\n",
    "def transformToDBR(uri):\n",
    "    if isinstance(uri, Literal):\n",
    "        # changes the literal to uppercase so that the object with the same name refers to an object and not the string\n",
    "        return uri.upper()\n",
    "    components = g.namespace_manager.compute_qname(uri)\n",
    "    return \"http://dbpedia.org/resource/%s\"%(components[2])\n",
    "\n",
    "# -------------------------\n",
    "\n",
    "g = Graph()\n",
    "load_graph(g, 'example-from-slides.ttl')\n",
    "serialize_graph(g)\n",
    "\n",
    "\n",
    "# Don't forget to run this cell before continuing the task.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Write a SPARQL query that finds all the cities in the dataset\n",
    "\n",
    "As you cannot directly use class City, you will have to find those cities in the dataset (example-from-slides.ttl) using implicit information that can be deduced from the domain and ranges of the relations (e.g. things in a hasCapital relation are capitals and a capital is a city, etc.).\n",
    "\n",
    "Save all the cities returned from the SPARQL query into the empty set \"cities\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://example.com/kad/Rotterdam\n",
      "http://example.com/kad/Berlin\n",
      "http://example.com/kad/Amsterdam\n"
     ]
    }
   ],
   "source": [
    "ex = Namespace(\"http://example.com/kad/\")\n",
    "cities = set()\n",
    "\n",
    "\n",
    "city_query = \"\"\"\n",
    "SELECT ?b\n",
    "WHERE {\n",
    "    ?p rdfs:subPropertyOf* ex:containsCity .\n",
    "    ?a ?p ?b .\n",
    "}\"\"\" \n",
    "\n",
    "qres = g.query(city_query)\n",
    "for row in qres:\n",
    "    cities.add(row.b)\n",
    "\n",
    "for city in cities:\n",
    "    print(city) \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. For each city, find from DBpedia its longitude & latitude, and its number of inhabitants (if available)\n",
    "\n",
    "Don't forget to adapt the namespace of the cities in your dataset when querying DBpedia, using the above function *transformToDBR(uri)*. Also note that namespaces should never use the *https* protocol.\n",
    "\n",
    "The empty graph h should only contain the triples extracted from DBpedia, but added to the URIs with the 'ex' namespace. \n",
    "An example of a triple in h is the following triple: \n",
    "       \n",
    "       ex:Amsterdam dbo:populationTotal \"872680\"^^xsd:nonNegativeInteger ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@prefix dbo: <http://dbpedia.org/ontology/> .\n",
      "@prefix ex: <http://example.com/kad/> .\n",
      "@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .\n",
      "\n",
      "ex:Amsterdam dbo:populationTotal \"872680\"^^xsd:nonNegativeInteger .\n",
      "\n",
      "ex:Berlin dbo:populationTotal \"3769495\"^^xsd:nonNegativeInteger .\n",
      "\n",
      "ex:Rotterdam dbo:populationTotal \"651157\"^^xsd:nonNegativeInteger .\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "h = Graph()\n",
    "h.bind(\"ex\", Namespace(\"http://example.com/kad/\"))\n",
    "h.bind(\"dbo\", Namespace(\"http://dbpedia.org/ontology/\"))\n",
    "\n",
    "dbo = Namespace(\"http://dbpedia.org/ontology/\")\n",
    "\n",
    "for city in cities:\n",
    "    url = transformToDBR(city)\n",
    "    sparql = SPARQLWrapper(\"http://dbpedia.org/sparql\")\n",
    "\n",
    "    sparql.setQuery(f\"\"\"\n",
    "        PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "        PREFIX dbo: <http://dbpedia.org/ontology/>\n",
    "\n",
    "        SELECT ?o\n",
    "        WHERE {{ \n",
    "            <{url}> dbo:populationTotal ?o \n",
    "        }}\n",
    "    \"\"\")\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    results = sparql.query().convert()\n",
    "    for result in results[\"results\"][\"bindings\"]:\n",
    "        h.add((city, dbo.populationTotal, Literal(result['o']['value'], datatype=result['o']['datatype'])))\n",
    "serialize_graph(h)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Save your results\n",
    "\n",
    "- Merge the triples from example-from-slides.ttl with the information extracted from DBpedia\n",
    "- Save all these triples into a new file 'extended-example.ttl'\n",
    "- Print all triples in Turtle Syntax.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@prefix ns1: <http://example.com/kad/> .\n",
      "@prefix ns2: <http://dbpedia.org/ontology/> .\n",
      "@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .\n",
      "@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .\n",
      "\n",
      "ns1:Netherlands a ns1:Country ;\n",
      "    ns1:contains ns1:Ijsselmeer ;\n",
      "    ns1:containsCity ns1:Rotterdam ;\n",
      "    ns1:hasCapital ns1:Amsterdam ;\n",
      "    ns1:hasName \"The Netherlands\" ;\n",
      "    ns1:neighbours ns1:Belgium .\n",
      "\n",
      "ns1:hasCapital rdfs:range ns1:Capital ;\n",
      "    rdfs:subPropertyOf ns1:containsCity .\n",
      "\n",
      "ns1:neighbours rdfs:subPropertyOf ns1:closeBy .\n",
      "\n",
      "ns1:Amsterdam a ns1:Capital ;\n",
      "    ns2:populationTotal \"872680\"^^xsd:nonNegativeInteger ;\n",
      "    ns1:closeBy ns1:Germany .\n",
      "\n",
      "ns1:Belgium a ns1:Country .\n",
      "\n",
      "ns1:Berlin ns2:populationTotal \"3769495\"^^xsd:nonNegativeInteger .\n",
      "\n",
      "ns1:EuropeanCountry rdfs:subClassOf ns1:Country .\n",
      "\n",
      "ns1:Germany a ns1:EuropeanCountry ;\n",
      "    ns1:hasCapital ns1:Berlin .\n",
      "\n",
      "ns1:Rotterdam ns2:populationTotal \"651157\"^^xsd:nonNegativeInteger .\n",
      "\n",
      "ns1:closeBy rdfs:domain ns1:Location ;\n",
      "    rdfs:range ns1:Location .\n",
      "\n",
      "ns1:containsCity rdfs:domain ns1:Country ;\n",
      "    rdfs:range ns1:City ;\n",
      "    rdfs:subPropertyOf ns1:contains .\n",
      "\n",
      "ns1:Capital rdfs:subClassOf ns1:City .\n",
      "\n",
      "ns1:City rdfs:subClassOf ns1:Location .\n",
      "\n",
      "ns1:Country rdfs:subClassOf ns1:Location .\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "merged_graph = Graph()\n",
    "merged_graph += g\n",
    "merged_graph += h\n",
    "\n",
    "merged_graph.serialize(destination=\"extended-example.ttl\")\n",
    "serialize_graph(merged_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: (3 points)  Implement Basic Inferencing Rules "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the lecture we showed that the RDFS inference rules can be used to infer new knowledge. For example, infer class membership based on rdfs:domain or infer relationships between subjects and objects based on rdfs:subPropertyOf. \n",
    "\n",
    "Create rules to inference class membership based on the RDF Schema language features \n",
    "*\tFor example: infer that an instance belongs to a class because of domain and range restrictions\n",
    "*\tFor example: infer that an instance belongs to a (super)class because it also belongs to a subclass\n",
    "\n",
    "We implemented the rdfs2 rule. You should implement the 5 following remaining rules:  \n",
    "\n",
    "*     (rdfs2) If G contains the triples (aaa rdfs:domain xxx.) and (uuu aaa yyy.)  then infer the triple (uuu rdf:type xxx.)\n",
    "*     (rdfs3) If G contains the triples (aaa rdfs:range xxx.) and (uuu aaa vvv.) then infer the triple (vvv rdf:type xxx .)\n",
    "*     (rdfs5) If G contains the triples (uuu rdfs:subPropertyOf vvv.) and (vvv rdfs:subPropertyOf xxx.) then infer the triple\n",
    "(uuu rdfs:subPropertyOf xxx.) \n",
    "*     (rdfs7) If G contains the triples (aaa rdfs:subPropertyOf bbb.) and (uuu aaa yyy.) then infer the triple (uuu bbb yyy) \n",
    "*     (rdfs9) If G contains the triples (uuu rdfs:subClassOf xxx.) and (vvv rdf:type uuu.) then infer the triple\n",
    " (vvv rdf:type xxx.)   -> this one was not mentioned in the lecture, but is a very important one. \n",
    "*     (rdfs11) If G contains the triples (uuu rdfs:subClassOf vvv.) and (vvv rdfs:subClassOf xxx.) then infer the triple\n",
    "(uuu rdfs:subClassOf xxx.)\n",
    "\n",
    "\n",
    "Run your rule reasoner on your knowledge graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(rdfs 3)  http://example.com/kad/Rotterdam rdf:type http://example.com/kad/City\n",
      "(rdfs 7)  http://example.com/kad/Netherlands http://example.com/kad/closeBy http://example.com/kad/Belgium\n",
      "(rdfs 9)  http://example.com/kad/Netherlands rdf:type http://example.com/kad/Location\n",
      "(rdfs 9)  http://example.com/kad/Belgium rdf:type http://example.com/kad/Location\n",
      "(rdfs 9)  http://example.com/kad/Amsterdam rdf:type http://example.com/kad/City\n",
      "(rdfs 11)  http://example.com/kad/Capital rdfs:subClassOf http://example.com/kad/Location\n",
      "(rdfs 5)  http://example.com/kad/hasCapital rdfs:subPropertyOf http://example.com/kad/contains\n",
      "(rdfs 7)  http://example.com/kad/Netherlands http://example.com/kad/containsCity http://example.com/kad/Amsterdam\n",
      "(rdfs 7)  http://example.com/kad/Germany http://example.com/kad/containsCity http://example.com/kad/Berlin\n",
      "(rdfs 2)  http://example.com/kad/Amsterdam rdf:type http://example.com/kad/Location\n",
      "(rdfs 3)  http://example.com/kad/Germany rdf:type http://example.com/kad/Location\n",
      "(rdfs 2)  http://example.com/kad/Netherlands rdf:type http://example.com/kad/Country\n",
      "(rdfs 3)  http://example.com/kad/Amsterdam rdf:type http://example.com/kad/Capital\n",
      "(rdfs 3)  http://example.com/kad/Berlin rdf:type http://example.com/kad/Capital\n",
      "(rdfs 9)  http://example.com/kad/Germany rdf:type http://example.com/kad/Country\n",
      "(rdfs 11)  http://example.com/kad/EuropeanCountry rdfs:subClassOf http://example.com/kad/Location\n",
      "(rdfs 7)  http://example.com/kad/Netherlands http://example.com/kad/contains http://example.com/kad/Rotterdam\n",
      "---------------------------------\n",
      "Number of inferred triples: 17\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "def myRDFSreasoner(myGraph):\n",
    "    inferredTriples = 0\n",
    "    for sbj, prd, obj in myGraph:\n",
    "        # --- rdfs2 ---\n",
    "        if (prd.eq(URIRef(\"http://www.w3.org/2000/01/rdf-schema#domain\"))):\n",
    "            generator = myGraph.subject_objects(URIRef(sbj))\n",
    "            for s, o in generator:\n",
    "                    inferredTriples += 1\n",
    "                    print(\"(rdfs 2) \", s, \"rdf:type\", obj)\n",
    "              \n",
    "        # --- rdfs3 ---\n",
    "        if (prd.eq(RDFS.range)):\n",
    "            generator = myGraph.subject_objects(URIRef(sbj))\n",
    "            for s, o in generator:\n",
    "                    inferredTriples += 1\n",
    "                    print(\"(rdfs 3) \", o, \"rdf:type\", obj)\n",
    "              \n",
    "        # --- rdfs5 ---\n",
    "        if (prd.eq(RDFS.subPropertyOf)):\n",
    "            generator = myGraph.objects(URIRef(obj), RDFS.subPropertyOf)\n",
    "            for o in generator:\n",
    "                    inferredTriples += 1\n",
    "                    print(\"(rdfs 5) \", sbj, \"rdfs:subPropertyOf\", o)\n",
    "              \n",
    "        # --- rdfs7 ---\n",
    "        if (prd.eq(RDFS.subPropertyOf)):\n",
    "            generator = myGraph.subject_objects(URIRef(sbj))\n",
    "            for s, o in generator:\n",
    "                    inferredTriples += 1\n",
    "                    print(\"(rdfs 7) \", s, obj, o)\n",
    "         \n",
    "        # --- rdfs9 ---\n",
    "        if (prd.eq(RDFS.subClassOf)):\n",
    "            generator = myGraph.subjects(RDF.type, URIRef(sbj))\n",
    "            for s in generator:\n",
    "                    inferredTriples += 1\n",
    "                    print(\"(rdfs 9) \", s, \"rdf:type\", obj)\n",
    "    \n",
    "        # --- rdfs11 ---\n",
    "        if (prd.eq(RDFS.subClassOf)):\n",
    "            generator = myGraph.objects(URIRef(obj), RDFS.subClassOf)\n",
    "            for o in generator:\n",
    "                    inferredTriples += 1\n",
    "                    print(\"(rdfs 11) \", sbj, \"rdfs:subClassOf\", o)\n",
    "        \n",
    "    print(\"---------------------------------\")\n",
    "    print(\"Number of inferred triples:\", inferredTriples)\n",
    "    print(\"---------------------------------\")\n",
    "    \n",
    "myRDFSreasoner(g)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: (2 points) Build your very own RDFS knowledge graph. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a small RDF Schema vocabulary in Turtle. You can choose your own domain (e.g. movies, geography, sports) respecting all the following rules:\n",
    "*\tThe schema should define at least 4 classes, 4 properties, and 4 instances.\n",
    "*   The properties should be used to relate the instances\n",
    "*\tThe instances should be a member of your classes\n",
    "*\tAll resources should have an rdfs:label in a suitable language.\n",
    "\n",
    "You should use (at least) the following language features of RDF and RDFS:\n",
    "* \trdf:type (or 'a')\n",
    "* \trdfs:subClassOf\n",
    "* \trdfs:subPropertyOf\n",
    "* \trdfs:domain and rdfs:range\n",
    "*\trdfs:label\n",
    "\n",
    "Be sure to define the 'rdf:' and 'rdfs:' namespace prefixes for RDF and RDF Schema in your file (perhaps have a look at http://prefix.cc)\n",
    "\n",
    "For creating your vocabulary, you can either use a text editor, or add the axioms directly (programatically) to your Knowledge Graph as you did last week. \n",
    "\n",
    "Play around with the inference rules you have created in the previous task to make sure that you some added some implicit knowledge, that becomes \"visible\" via inferencing (this will be useful for the next task). \n",
    "\n",
    "Finally:\n",
    "- Add the knowledge you created into the RDFLIB graph datastructure *myRDFSgraph*, \n",
    "- Print *myRDFSgraph* in Turtle so that we can check your \"design\"\n",
    "- Save *myRDFSgraph* into a new file 'myRDFSgraph.ttl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now let's check what we can infer from your knowledge graph...\n",
      "The more rules you cover, the better!\n",
      "(rdfs 2)  http://example.com/kad/The_Travelling_Cat_Chronicles rdf:type http://example.com/kad/Book\n",
      "(rdfs 3)  2012-11-01 rdf:type http://www.w3.org/2001/XMLSchema#date\n",
      "(rdfs 2)  http://example.com/kad/The_Travelling_Cat_Chronicles rdf:type http://example.com/kad/Book\n",
      "(rdfs 7)  http://example.com/kad/The_Travelling_Cat_Chronicles http://example.com/kad/hasDetail http://example.com/kad/Hiro_Arikawa\n",
      "(rdfs 3)  http://example.com/kad/Hiro_Arikawa rdf:type http://example.com/kad/Author\n",
      "(rdfs 9)  http://example.com/kad/Hiro_Arikawa rdf:type http://example.com/kad/Person\n",
      "(rdfs 7)  http://example.com/kad/The_Travelling_Cat_Chronicles http://example.com/kad/hasDetail http://example.com/kad/Fiction\n",
      "(rdfs 3)  Hiro Arikawa rdf:type http://www.w3.org/2001/XMLSchema#string\n",
      "(rdfs 3)  Fiction rdf:type http://www.w3.org/2001/XMLSchema#string\n",
      "(rdfs 3)  Viking rdf:type http://www.w3.org/2001/XMLSchema#string\n",
      "(rdfs 3)  http://example.com/kad/Fiction rdf:type http://example.com/kad/Genre\n",
      "(rdfs 2)  http://example.com/kad/The_Travelling_Cat_Chronicles rdf:type http://example.com/kad/Book\n",
      "(rdfs 3)  The Traveling Cat Chronicles rdf:type http://www.w3.org/2001/XMLSchema#string\n",
      "(rdfs 3)  http://example.com/kad/Viking rdf:type http://example.com/kad/Publisher\n",
      "(rdfs 2)  http://example.com/kad/The_Travelling_Cat_Chronicles rdf:type http://example.com/kad/Book\n",
      "(rdfs 7)  http://example.com/kad/The_Travelling_Cat_Chronicles http://example.com/kad/hasDetail The Traveling Cat Chronicles\n",
      "(rdfs 7)  http://example.com/kad/The_Travelling_Cat_Chronicles http://example.com/kad/hasDetail 2012-11-01\n",
      "(rdfs 2)  http://example.com/kad/The_Travelling_Cat_Chronicles rdf:type http://example.com/kad/Book\n",
      "(rdfs 7)  http://example.com/kad/The_Travelling_Cat_Chronicles http://example.com/kad/hasDetail http://example.com/kad/Viking\n",
      "---------------------------------\n",
      "Number of inferred triples: 19\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "myRDFSgraph = Graph()\n",
    "load_graph(myRDFSgraph, 'myRDFSgraph.ttl')\n",
    "\n",
    "print(\"Now let's check what we can infer from your knowledge graph...\")\n",
    "print(\"The more rules you cover, the better!\")\n",
    "myRDFSreasoner(myRDFSgraph)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4 (2 points) Compare local inferences with GraphDB results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload *myRDFSgraph.ttl* to GraphDB (check [the GraphDB tutorial](https://github.com/ucds-vu/knowledge-data-vu/blob/master/Tutorials/Preliminaries/tutorial-GraphDB.md) before starting to work with GraphDB).\n",
    "\n",
    "Formulate two different SPARQL queries, and write a Python code that executes these queries over your GraphDB SPARQL endpoint (check example of Task 1).\n",
    "\n",
    "**Each SPARQL query should return a different type of inferred knowledge** (at least one triple that was not explicitly asserted in the graph).\n",
    "\n",
    "Specify below next to your query, which type of RDFS rule is the GraphDB reasoner using to infer this answer (rdfs2, rdfs3, rdfs5, rdfs7, rdfs9, rdfs11). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get your GraphDB repository URL (setup -> repositories -> repository url) and assign it to the variable 'myEndpoint' below. \n",
    "# It should be similar to this: \n",
    "\n",
    "myEndpoint = \"http://LAPTOP-V7BUQDEO:7200/repositories/KnowlegdeAndData\"  # KnowledgeAndData is the name of the repository\n",
    "sparql = SPARQLWrapper(myEndpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://example.com/kad/Hiro_Arikawa a http://example.com/kad/Person\n"
     ]
    }
   ],
   "source": [
    "# Query 1 - rdfs 9: \n",
    "\n",
    "# Check example of Task 1 on how to query remote SPARQL endpoints\n",
    "\n",
    "sparql.setQuery(\"\"\"\n",
    "    PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "    PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "\n",
    "    select ?vvv ?xxx \n",
    "    from default\n",
    "    where { \n",
    "        ?uuu rdfs:subClassOf ?xxx .\n",
    "        ?vvv rdf:type ?uuu .\n",
    "        \n",
    "    }\n",
    "\"\"\")\n",
    "\n",
    "sparql.setReturnFormat(JSON)\n",
    "results = sparql.query().convert()\n",
    "for result in results[\"results\"][\"bindings\"]:\n",
    "    print(f'{result[\"vvv\"][\"value\"]} a {result[\"xxx\"][\"value\"]}') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://example.com/kad/The_Travelling_Cat_Chronicles http://example.com/kad/hasDetail http://example.com/kad/Hiro_Arikawa\n",
      "http://example.com/kad/The_Travelling_Cat_Chronicles http://example.com/kad/hasDetail The Traveling Cat Chronicles\n",
      "http://example.com/kad/The_Travelling_Cat_Chronicles http://example.com/kad/hasDetail http://example.com/kad/Viking\n",
      "http://example.com/kad/The_Travelling_Cat_Chronicles http://example.com/kad/hasDetail 2012-11-01\n",
      "http://example.com/kad/The_Travelling_Cat_Chronicles http://example.com/kad/hasDetail http://example.com/kad/Fiction\n"
     ]
    }
   ],
   "source": [
    "# Query 2 - rdfs 7 \n",
    "\n",
    "# Check example of Task 1 on how to query remote SPARQL endpoints\n",
    "\n",
    "sparql.setQuery(\"\"\"\n",
    "    PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "    PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "\n",
    "    select ?uuu ?bbb ?yyy \n",
    "    from default\n",
    "    where { \n",
    "        ?aaa rdfs:subPropertyOf ?bbb .\n",
    "        ?uuu ?aaa ?yyy .\n",
    "        \n",
    "    }\n",
    "\"\"\")\n",
    "\n",
    "sparql.setReturnFormat(JSON)\n",
    "results = sparql.query().convert()\n",
    "for result in results[\"results\"][\"bindings\"]:\n",
    "    print(f'{result[\"uuu\"][\"value\"]} {result[\"bbb\"][\"value\"]} {result[\"yyy\"][\"value\"]}') \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit ('knowledge': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "6681cf610ed5d2e426915c441f107f60650022717e9601554b61a1796743a8f7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
